Modern Open Gl Notes:

1) We use GLEW in order to gain access to moder OpenGL functions that re inside the drivers on our graphics card
2) Rendering something on screen seems to be split into 3 parts vertex buffers, vertex attributes, and shaders
3) When we reference data in opengl that data is loaded into a buffer, which is just a chunk of memory we specify 
4) That buffer is given a certain ID number for reference

Vertext Attribute notes: 
1) In order to have our gpu actually know what to do with this data we need to use some methods to define and sort the structure of the data into 
2) There may be times in which offsets have to be defined using void pointer casts such as (const void*) 8 to specify 8 bytes

Shader notes:
1) A shader is basically just a program that is run on our gpu where we write it, compile it and link it like any other program but run it on our gpu
2) We want to be able to program the gpu in order to make use of its power
3) 2 main types of shaders vertex shaders and fragment shaders, there are others but these are the most common used ones
4) The general simplist order of steps is DrawCall->Vertex Shader-> Fragment Shader->Result On Screen
5) Vertex shader is called per vertex to be renedered and it's main responsibility is to determine where/put the vertex on the screeen in screenspace
6) The fragment shader is responsible for rasterizing the pixels in our objects. Thinkng back to the one triangle example it would draw the shape of the triangle by 
	filling in the inside of the triangle with color which is called rasterizing
7) The fragment shader will be called once per pixel needing to be colored
8) Ideally this means more calculations want to be done in the vertex shader since it will be called less 
9) Though there are specific things that should be done in the fragment shader such as lighting 

Error Handling Notes:
1) There are 2 general ways that this is commonly done either through gLGetError which returns the error code and has to be called multiple times per error 
or we can use glDebugMessageCallback

Vertex Array Notes
1) A Vertex Array is similar to a vertex buffer but with some minor differences
2) The first difference is that with a vertex Array we do not have to bind a vertex attribute pointer every time we draw
3) The second difference is that a Vertex Array allows us to have multiple meshes on screen at the same time
4) In order to make use of a Vertex array object we need to follow this order 
	-A) Create the Vertex Array Object and Bind it 
	-B) Create a number of buffers and for each buffer enable the attribute array and specify the vertex attribute as an index in the array
		- Done using glEnableVertexAttribArray and glVertexAttribPointer

Blending- This a term for determining how we take two separate colors and have them interact or how they are ordered in a space
	How to use blending:
		1) Use glEnable(GL_BLEND) or glDisable(GL_BLEND)
		2) Use glBlendFunc(src,dest)
			src= how the src RGBA factor is computed(default value is GL_ONE)
			dest= how the dest RGBA factor is computed (default value is GL_ZERO)
		3) glBlendEquation(mode)
			mode=how we combine the src and dest colors
			Default value is GL_FUNC_ADD

Projection Matrix- Typically when it comes to translating objecs from a world space to a screen projection or screen space we typically use a projection matrix
	1) When it comes to using this we end up with values that fall in between -1 and 1 with them representing values on an axis (-1 is left/down and 1 is right/up)
	2) We generally have 2 types of projection Orthogonal and Perspective
		Orthogonal is a type of projection that does not display depth based on distance to camera and is typically but not always used fr 2D
		Perspective is a type of projection that does display depth based on distance from the camera so that further away objects appear smaller
	3) Anything that is larger or smaller than the -1 to 1 scope then that part or area of an object(s) is not rendered
	4) Our Orthogonal/Perspective matrix is what defines the range for the world space and could be anyhting depending on what we want
		Ex: if we have 720 by 480 window than we could define it like ortho(left,rightdown,up) to be ortho(0,720,0,480) and that would be the scale for the objects size on screen
			aka if with this size a square with vertx positions that yield an area of 1 would be too small to see but if they are positioned well with a larger range 
			they are more visible
	5) At the end f the day though regardless of how we size our projection matrix the end result for our vertex positions on screen will still be in 
		a range of -1 to 1 for each axisvalue

Model View Projection- Is a set of matrices that define how vertices of a model or object is projected on the screen for rendering a view
	1) View Matrix- The view matrix is a matrix responsible for helping translate vertices for camera space aka what the camera actually sees
		-Includes rotation, position, scale of camera
	2) Model Matrix- The model matrix is responsible for helping translate vertices for models in world space
		-Includes position, rotation and scale
	3) It is when the model,view, and projection matices get multiplied together that we get the final result for vertex positions for a rendered frame
		Be aware that while all 3 are multiplied together the order is not always model then view then projection it can vary based on pipeline
	4) For respresnting a camera shift, we don't actually shift the camera we simply move every object around the camera instead
		-Ex: If we want to simulate the camera moving right then we will move every object left
